{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80a3e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e93cb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"resources/small_loans_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f701c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retypes={\n",
    "'loan_type':'str'\n",
    ",'loan_amount_000s':'int64'\n",
    ",'action_taken':'int8'\n",
    ",'applicant_ethnicity':'str'\n",
    ",'co_applicant_ethnicity':'str'\n",
    ",'applicant_race_1':'str'\n",
    ",'co_applicant_race_1':'str'\n",
    ",'applicant_sex':'str'\n",
    ",'co_applicant_sex':'str'\n",
    ",'applicant_income_000s':'int64'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9741763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical fields to strings for one-hot encoding\n",
    "df = df.astype(retypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33eafc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['action_taken','Unnamed: 0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52f65f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['loan_amount_000s', 'applicant_income_000s', 'loan_type_1',\n",
      "       'loan_type_2', 'loan_type_3', 'loan_type_4', 'applicant_ethnicity_1',\n",
      "       'applicant_ethnicity_2', 'co_applicant_ethnicity_1',\n",
      "       'co_applicant_ethnicity_2', 'co_applicant_ethnicity_5',\n",
      "       'applicant_race_1_1', 'applicant_race_1_2', 'applicant_race_1_3',\n",
      "       'applicant_race_1_4', 'applicant_race_1_5', 'co_applicant_race_1_1',\n",
      "       'co_applicant_race_1_2', 'co_applicant_race_1_3',\n",
      "       'co_applicant_race_1_4', 'co_applicant_race_1_5',\n",
      "       'co_applicant_race_1_8', 'applicant_sex_1', 'applicant_sex_2',\n",
      "       'co_applicant_sex_1', 'co_applicant_sex_2', 'co_applicant_sex_5'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amount_000s</th>\n",
       "      <th>applicant_income_000s</th>\n",
       "      <th>loan_type_1</th>\n",
       "      <th>loan_type_2</th>\n",
       "      <th>loan_type_3</th>\n",
       "      <th>loan_type_4</th>\n",
       "      <th>applicant_ethnicity_1</th>\n",
       "      <th>applicant_ethnicity_2</th>\n",
       "      <th>co_applicant_ethnicity_1</th>\n",
       "      <th>co_applicant_ethnicity_2</th>\n",
       "      <th>...</th>\n",
       "      <th>co_applicant_race_1_2</th>\n",
       "      <th>co_applicant_race_1_3</th>\n",
       "      <th>co_applicant_race_1_4</th>\n",
       "      <th>co_applicant_race_1_5</th>\n",
       "      <th>co_applicant_race_1_8</th>\n",
       "      <th>applicant_sex_1</th>\n",
       "      <th>applicant_sex_2</th>\n",
       "      <th>co_applicant_sex_1</th>\n",
       "      <th>co_applicant_sex_2</th>\n",
       "      <th>co_applicant_sex_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>337</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>236</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>126</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>156</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>71</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>738</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loan_amount_000s  applicant_income_000s  loan_type_1  loan_type_2  \\\n",
       "0                   176                    142            1            0   \n",
       "1                   143                     45            0            0   \n",
       "2                   337                    196            1            0   \n",
       "3                   119                     86            1            0   \n",
       "4                   218                     67            1            0   \n",
       "...                 ...                    ...          ...          ...   \n",
       "49995               236                     71            1            0   \n",
       "49996               126                     33            0            1   \n",
       "49997               156                     90            1            0   \n",
       "49998                71                     42            1            0   \n",
       "49999               738                    158            1            0   \n",
       "\n",
       "       loan_type_3  loan_type_4  applicant_ethnicity_1  applicant_ethnicity_2  \\\n",
       "0                0            0                      0                      1   \n",
       "1                1            0                      0                      1   \n",
       "2                0            0                      0                      1   \n",
       "3                0            0                      0                      1   \n",
       "4                0            0                      0                      1   \n",
       "...            ...          ...                    ...                    ...   \n",
       "49995            0            0                      0                      1   \n",
       "49996            0            0                      0                      1   \n",
       "49997            0            0                      0                      1   \n",
       "49998            0            0                      0                      1   \n",
       "49999            0            0                      0                      1   \n",
       "\n",
       "       co_applicant_ethnicity_1  co_applicant_ethnicity_2  ...  \\\n",
       "0                             0                         1  ...   \n",
       "1                             0                         0  ...   \n",
       "2                             0                         1  ...   \n",
       "3                             0                         1  ...   \n",
       "4                             0                         1  ...   \n",
       "...                         ...                       ...  ...   \n",
       "49995                         0                         0  ...   \n",
       "49996                         0                         0  ...   \n",
       "49997                         0                         0  ...   \n",
       "49998                         0                         0  ...   \n",
       "49999                         0                         0  ...   \n",
       "\n",
       "       co_applicant_race_1_2  co_applicant_race_1_3  co_applicant_race_1_4  \\\n",
       "0                          0                      0                      0   \n",
       "1                          0                      0                      0   \n",
       "2                          0                      0                      0   \n",
       "3                          0                      0                      0   \n",
       "4                          0                      0                      0   \n",
       "...                      ...                    ...                    ...   \n",
       "49995                      0                      0                      0   \n",
       "49996                      0                      0                      0   \n",
       "49997                      0                      0                      0   \n",
       "49998                      0                      0                      0   \n",
       "49999                      0                      0                      0   \n",
       "\n",
       "       co_applicant_race_1_5  co_applicant_race_1_8  applicant_sex_1  \\\n",
       "0                          1                      0                1   \n",
       "1                          0                      1                1   \n",
       "2                          1                      0                1   \n",
       "3                          1                      0                1   \n",
       "4                          1                      0                1   \n",
       "...                      ...                    ...              ...   \n",
       "49995                      0                      1                1   \n",
       "49996                      0                      1                1   \n",
       "49997                      0                      1                1   \n",
       "49998                      0                      1                1   \n",
       "49999                      0                      1                0   \n",
       "\n",
       "       applicant_sex_2  co_applicant_sex_1  co_applicant_sex_2  \\\n",
       "0                    0                   0                   1   \n",
       "1                    0                   0                   0   \n",
       "2                    0                   0                   1   \n",
       "3                    0                   0                   1   \n",
       "4                    0                   0                   1   \n",
       "...                ...                 ...                 ...   \n",
       "49995                0                   0                   0   \n",
       "49996                0                   0                   0   \n",
       "49997                0                   0                   0   \n",
       "49998                0                   0                   0   \n",
       "49999                1                   0                   0   \n",
       "\n",
       "       co_applicant_sex_5  \n",
       "0                       0  \n",
       "1                       1  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "49995                   1  \n",
       "49996                   1  \n",
       "49997                   1  \n",
       "49998                   1  \n",
       "49999                   1  \n",
       "\n",
       "[50000 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies = pd.get_dummies(X)\n",
    "print(X_dummies.columns)\n",
    "X_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c23c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "\n",
    "y = df['action_taken']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457bc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc4666f",
   "metadata": {},
   "source": [
    "## Baseline Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44046759",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [X_train_scaled, X_test_scaled, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03abb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data):\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test = data\n",
    "    reg = model.fit(X_train_scaled, y_train)\n",
    "    print(f'Model: {type(reg).__name__}')\n",
    "    print(f'Train score: {reg.score(X_train_scaled, y_train)}')\n",
    "    print(f'Test Score: {reg.score(X_test_scaled, y_test)}\\n')\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdae2bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LogisticRegression\n",
      "Train score: 0.8952266666666666\n",
      "Test Score: 0.89328\n",
      "\n",
      "Model: AdaBoostClassifier\n",
      "Train score: 0.8967733333333333\n",
      "Test Score: 0.89328\n",
      "\n",
      "Model: RandomForestClassifier\n",
      "Train score: 0.9933866666666666\n",
      "Test Score: 0.86944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LinearSVC\n",
      "Train score: 0.8952266666666666\n",
      "Test Score: 0.89328\n",
      "\n",
      "Model: DecisionTreeClassifier\n",
      "Train score: 0.9934666666666667\n",
      "Test Score: 0.8036\n",
      "\n",
      "Model: ExtraTreesClassifier\n",
      "Train score: 0.9934666666666667\n",
      "Test Score: 0.85632\n",
      "\n",
      "Model: KNeighborsClassifier\n",
      "Train score: 0.90128\n",
      "Test Score: 0.88456\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test defaults \n",
    "test_model(LogisticRegression(), data)\n",
    "test_model(AdaBoostClassifier(), data)\n",
    "test_model(RandomForestClassifier(), data)\n",
    "test_model(LinearSVC(), data)\n",
    "test_model(DecisionTreeClassifier(), data)\n",
    "test_model(ExtraTreesClassifier(), data)\n",
    "test_model(KNeighborsClassifier(), data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5afc60",
   "metadata": {},
   "source": [
    "### Grid CV of Best Performing Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ceaba",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d70169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   3.7s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   3.4s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   3.4s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   2.4s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   1.6s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   1.4s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   2.1s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   2.0s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   7.2s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   3.9s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   3.4s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   6.7s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   6.4s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   2.4s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   1.6s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   1.4s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   2.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   2.1s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   8.4s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   3.5s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   3.6s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   6.9s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   6.5s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   2.5s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   1.6s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   1.4s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   2.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   2.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   7.9s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   3.4s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   3.4s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   6.9s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   6.4s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   2.4s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   1.6s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   1.4s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   2.1s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   2.0s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   1.2s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   1.6s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   1.5s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   1.9s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   1.6s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.5s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   1.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   1.6s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   1.4s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   1.8s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   1.6s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.5s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   1.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   1.7s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   1.5s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   1.8s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   1.8s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.5s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.3s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   1.2s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   1.6s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   1.5s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   2.4s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   1.7s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.3s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.4s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.6s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.6s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=1500, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   0.3s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l1, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l1, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l2, solver=newton-cg;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.3s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l2, solver=sag;, score=0.895 total time=   0.2s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.2s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l2, solver=saga;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=l2, solver=liblinear;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.01, max_iter=2000, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "360 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan\n",
      "        nan        nan 0.89522667 0.89522667 0.89522667 0.89522667\n",
      " 0.89522667 0.89522667        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(random_state=1),\n",
       "             param_grid={'C': [1.0, 0.1, 0.01],\n",
       "                         'max_iter': [500, 1000, 1500, 2000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'solver': ['newton-cg', 'sag', 'saga', 'liblinear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= LogisticRegression(random_state=1)\n",
    "param_grid = {\n",
    "   'penalty':['l1', 'l2', 'elasticnet'],\n",
    "    'C': [1.0, 0.1, 0.01],\n",
    "    'solver': ['newton-cg', 'sag', 'saga', 'liblinear'],\n",
    "              'max_iter': [500, 1000, 1500, 2000]}\n",
    "lr_grid_clf = GridSearchCV(model, param_grid, verbose=3)\n",
    "lr_grid_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "231496cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.8952266666666666\n"
     ]
    }
   ],
   "source": [
    "print(lr_grid_clf.best_params_)\n",
    "print(lr_grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37164245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8952266666666666\n",
      "Testing Data Score: 0.89328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr_best_params=lr_grid_clf.best_params_\n",
    "lr_classifier= LogisticRegression(**lr_best_params, random_state=1).fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {lr_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {lr_classifier.score(X_test_scaled, y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e751132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print best to compare vs entire dataset\n",
    "pickle.dump(lr_classifier, open('Resources/lr_classifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b69f6f",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545318c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, n_estimators=100;, score=0.877 total time=   2.4s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, n_estimators=100;, score=0.878 total time=   2.1s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, n_estimators=100;, score=0.873 total time=   2.2s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, n_estimators=100;, score=0.878 total time=   2.2s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, n_estimators=100;, score=0.876 total time=   2.2s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, n_estimators=150;, score=0.878 total time=   3.2s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, n_estimators=150;, score=0.878 total time=   3.2s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, n_estimators=150;, score=0.872 total time=   3.2s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, n_estimators=150;, score=0.877 total time=   3.1s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, n_estimators=150;, score=0.876 total time=   3.1s\n",
      "[CV 1/5] END bootstrap=True, max_features=sqrt, n_estimators=200;, score=0.878 total time=   4.2s\n",
      "[CV 2/5] END bootstrap=True, max_features=sqrt, n_estimators=200;, score=0.878 total time=   4.1s\n",
      "[CV 3/5] END bootstrap=True, max_features=sqrt, n_estimators=200;, score=0.873 total time=   4.1s\n",
      "[CV 4/5] END bootstrap=True, max_features=sqrt, n_estimators=200;, score=0.877 total time=   4.2s\n",
      "[CV 5/5] END bootstrap=True, max_features=sqrt, n_estimators=200;, score=0.877 total time=   4.2s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, n_estimators=100;, score=0.876 total time=   2.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, n_estimators=100;, score=0.878 total time=   2.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, n_estimators=100;, score=0.873 total time=   2.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, n_estimators=100;, score=0.877 total time=   2.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, n_estimators=100;, score=0.877 total time=   2.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, n_estimators=150;, score=0.876 total time=   3.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, n_estimators=150;, score=0.878 total time=   3.0s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, n_estimators=150;, score=0.873 total time=   3.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, n_estimators=150;, score=0.878 total time=   3.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, n_estimators=150;, score=0.878 total time=   3.0s\n",
      "[CV 1/5] END bootstrap=True, max_features=log2, n_estimators=200;, score=0.877 total time=   4.0s\n",
      "[CV 2/5] END bootstrap=True, max_features=log2, n_estimators=200;, score=0.878 total time=   3.9s\n",
      "[CV 3/5] END bootstrap=True, max_features=log2, n_estimators=200;, score=0.873 total time=   4.0s\n",
      "[CV 4/5] END bootstrap=True, max_features=log2, n_estimators=200;, score=0.878 total time=   4.0s\n",
      "[CV 5/5] END bootstrap=True, max_features=log2, n_estimators=200;, score=0.878 total time=   4.0s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, n_estimators=100;, score=0.851 total time=   3.1s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, n_estimators=100;, score=0.848 total time=   3.1s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, n_estimators=100;, score=0.842 total time=   3.1s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, n_estimators=100;, score=0.851 total time=   3.1s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, n_estimators=100;, score=0.852 total time=   3.1s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, n_estimators=150;, score=0.851 total time=   4.7s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, n_estimators=150;, score=0.850 total time=   4.7s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, n_estimators=150;, score=0.843 total time=   4.7s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, n_estimators=150;, score=0.851 total time=   4.8s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, n_estimators=150;, score=0.853 total time=   4.7s\n",
      "[CV 1/5] END bootstrap=False, max_features=sqrt, n_estimators=200;, score=0.851 total time=   6.4s\n",
      "[CV 2/5] END bootstrap=False, max_features=sqrt, n_estimators=200;, score=0.850 total time=   6.4s\n",
      "[CV 3/5] END bootstrap=False, max_features=sqrt, n_estimators=200;, score=0.843 total time=   6.9s\n",
      "[CV 4/5] END bootstrap=False, max_features=sqrt, n_estimators=200;, score=0.850 total time=   7.6s\n",
      "[CV 5/5] END bootstrap=False, max_features=sqrt, n_estimators=200;, score=0.853 total time=   6.8s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, n_estimators=100;, score=0.851 total time=   3.2s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, n_estimators=100;, score=0.850 total time=   3.5s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, n_estimators=100;, score=0.843 total time=   3.3s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, n_estimators=100;, score=0.850 total time=   3.2s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, n_estimators=100;, score=0.852 total time=   3.1s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, n_estimators=150;, score=0.851 total time=   4.7s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, n_estimators=150;, score=0.849 total time=   5.2s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, n_estimators=150;, score=0.842 total time=   4.9s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, n_estimators=150;, score=0.851 total time=   5.2s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, n_estimators=150;, score=0.852 total time=   4.9s\n",
      "[CV 1/5] END bootstrap=False, max_features=log2, n_estimators=200;, score=0.851 total time=   6.7s\n",
      "[CV 2/5] END bootstrap=False, max_features=log2, n_estimators=200;, score=0.851 total time=   6.8s\n",
      "[CV 3/5] END bootstrap=False, max_features=log2, n_estimators=200;, score=0.843 total time=   6.5s\n",
      "[CV 4/5] END bootstrap=False, max_features=log2, n_estimators=200;, score=0.850 total time=   7.6s\n",
      "[CV 5/5] END bootstrap=False, max_features=log2, n_estimators=200;, score=0.852 total time=   9.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(random_state=1),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 150, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= RandomForestClassifier(random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100,150,200],\n",
    "    'bootstrap' : [True, False],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "rf_grid_clf = GridSearchCV(model, param_grid, verbose=3)\n",
    "rf_grid_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8947050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_features': 'log2', 'n_estimators': 200}\n",
      "0.8769866666666667\n"
     ]
    }
   ],
   "source": [
    "print(rf_grid_clf.best_params_)\n",
    "print(rf_grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4044a257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9934666666666667\n",
      "Testing Data Score: 0.8696\n"
     ]
    }
   ],
   "source": [
    "rf_best_params=rf_grid_clf.best_params_\n",
    "rf_classifier= RandomForestClassifier(**rf_best_params, random_state=1).fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {rf_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {rf_classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6cba8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_classifier, open('Resources/rf_classifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2fa45",
   "metadata": {},
   "source": [
    "#### Ada Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb3fff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.4s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.5s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.9s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.5s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.4s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  10.9s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  10.9s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  11.2s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  12.2s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  11.2s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  16.2s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  14.9s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  13.9s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  14.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  13.8s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1000;, score=0.895 total time=   9.3s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1000;, score=0.895 total time=   9.3s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1000;, score=0.895 total time=   9.3s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1000;, score=0.895 total time=   9.4s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1000;, score=0.895 total time=   9.3s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1500;, score=0.895 total time=  13.9s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1500;, score=0.895 total time=  13.9s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1500;, score=0.895 total time=  13.9s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1500;, score=0.895 total time=  13.9s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.01, n_estimators=1500;, score=0.895 total time=  13.9s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=500;, score=0.895 total time=   4.6s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=500;, score=0.895 total time=   4.7s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=500;, score=0.895 total time=   4.6s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1000;, score=0.895 total time=   9.2s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1000;, score=0.895 total time=   9.2s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1000;, score=0.895 total time=   9.3s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1000;, score=0.895 total time=   9.3s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1000;, score=0.895 total time=   9.2s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1500;, score=0.896 total time=  14.3s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1500;, score=0.896 total time=  14.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1500;, score=0.896 total time=  14.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1500;, score=0.895 total time=  14.3s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.1, n_estimators=1500;, score=0.895 total time=  13.7s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=500;, score=0.897 total time=   5.4s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=500;, score=0.896 total time=   5.3s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=500;, score=0.896 total time=   5.5s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=500;, score=0.896 total time=   5.4s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=500;, score=0.897 total time=   5.4s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1000;, score=0.896 total time=  11.2s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1000;, score=0.896 total time=  11.0s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1000;, score=0.896 total time=  11.3s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1000;, score=0.896 total time=  11.2s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1000;, score=0.897 total time=  11.0s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1500;, score=0.896 total time=  16.8s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1500;, score=0.896 total time=  16.8s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1500;, score=0.896 total time=  17.2s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1500;, score=0.896 total time=  17.0s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.5, n_estimators=1500;, score=0.897 total time=  17.3s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=500;, score=0.896 total time=   5.6s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=500;, score=0.896 total time=   5.7s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=500;, score=0.896 total time=   5.5s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=500;, score=0.896 total time=   5.7s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=500;, score=0.897 total time=   5.7s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1000;, score=0.896 total time=  12.8s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1000;, score=0.896 total time=  11.4s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1000;, score=0.896 total time=  11.6s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1000;, score=0.896 total time=  11.6s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1000;, score=0.897 total time=  11.5s\n",
      "[CV 1/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1500;, score=0.896 total time=  17.8s\n",
      "[CV 2/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1500;, score=0.896 total time=  17.1s\n",
      "[CV 3/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1500;, score=0.896 total time=  14.1s\n",
      "[CV 4/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1500;, score=0.896 total time=  13.8s\n",
      "[CV 5/5] END algorithm=SAMME, learning_rate=0.7, n_estimators=1500;, score=0.897 total time=  13.9s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.8s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.8s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.8s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.9s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=500;, score=0.895 total time=   5.6s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  11.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  11.7s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  11.5s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  11.4s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1000;, score=0.895 total time=  11.4s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  17.6s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  17.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  17.4s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  18.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.001, n_estimators=1500;, score=0.895 total time=  17.9s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=500;, score=0.896 total time=   5.8s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=500;, score=0.895 total time=   6.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=500;, score=0.896 total time=   5.9s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=500;, score=0.895 total time=   5.9s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=500;, score=0.896 total time=   5.7s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1000;, score=0.897 total time=  11.8s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1000;, score=0.897 total time=  11.8s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1000;, score=0.896 total time=  11.5s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1000;, score=0.896 total time=  12.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1000;, score=0.897 total time=  11.9s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1500;, score=0.896 total time=  17.5s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1500;, score=0.897 total time=  17.5s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1500;, score=0.896 total time=  17.4s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1500;, score=0.896 total time=  17.3s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.01, n_estimators=1500;, score=0.897 total time=  17.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=500;, score=0.896 total time=   5.7s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=500;, score=0.897 total time=   5.7s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=500;, score=0.896 total time=   5.6s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=500;, score=0.896 total time=   5.6s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=500;, score=0.897 total time=   5.6s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1000;, score=0.896 total time=  11.3s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1000;, score=0.897 total time=  11.4s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1000;, score=0.896 total time=  11.4s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1000;, score=0.896 total time=  11.8s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1000;, score=0.897 total time=  11.6s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1500;, score=0.896 total time=  16.9s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1500;, score=0.897 total time=  17.1s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1500;, score=0.896 total time=  17.3s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1500;, score=0.896 total time=  17.9s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.1, n_estimators=1500;, score=0.897 total time=  17.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=500;, score=0.896 total time=   5.8s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=500;, score=0.897 total time=   5.7s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=500;, score=0.896 total time=   5.8s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=500;, score=0.895 total time=   5.8s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=500;, score=0.897 total time=   5.6s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1000;, score=0.896 total time=  11.3s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1000;, score=0.897 total time=  11.4s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1000;, score=0.896 total time=  11.3s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1000;, score=0.895 total time=  11.6s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1000;, score=0.896 total time=  11.5s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1500;, score=0.896 total time=  17.1s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1500;, score=0.897 total time=  17.5s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1500;, score=0.896 total time=  17.0s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1500;, score=0.895 total time=  17.0s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.5, n_estimators=1500;, score=0.897 total time=  16.9s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=500;, score=0.896 total time=   5.7s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=500;, score=0.897 total time=   5.7s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=500;, score=0.896 total time=   5.6s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=500;, score=0.895 total time=   5.6s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=500;, score=0.897 total time=   5.6s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1000;, score=0.895 total time=  11.3s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1000;, score=0.897 total time=  11.4s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1000;, score=0.896 total time=  11.6s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1000;, score=0.895 total time=  11.7s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1000;, score=0.897 total time=  12.1s\n",
      "[CV 1/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1500;, score=0.895 total time=  17.2s\n",
      "[CV 2/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1500;, score=0.897 total time=  17.0s\n",
      "[CV 3/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1500;, score=0.896 total time=  17.2s\n",
      "[CV 4/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1500;, score=0.895 total time=  17.1s\n",
      "[CV 5/5] END algorithm=SAMME.R, learning_rate=0.7, n_estimators=1500;, score=0.897 total time=  16.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostClassifier(random_state=1),\n",
       "             param_grid={'algorithm': ['SAMME', 'SAMME.R'],\n",
       "                         'learning_rate': [0.001, 0.01, 0.1, 0.5, 0.7],\n",
       "                         'n_estimators': [500, 1000, 1500]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= AdaBoostClassifier(random_state=1)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.5, 0.7],\n",
    "    'algorithm':['SAMME', 'SAMME.R'],\n",
    "    'n_estimators': [500, 1000, 1500]\n",
    "}\n",
    "ab_grid_clf = GridSearchCV(model, param_grid, verbose=3)\n",
    "ab_grid_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e74473f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'SAMME.R', 'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.8966133333333334\n"
     ]
    }
   ],
   "source": [
    "print(ab_grid_clf.best_params_)\n",
    "print(ab_grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b24ce990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8965866666666666\n",
      "Testing Data Score: 0.8936\n"
     ]
    }
   ],
   "source": [
    "ab_best_params=ab_grid_clf.best_params_\n",
    "ab_classifier= AdaBoostClassifier(**ab_best_params, random_state=1).fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {ab_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {ab_classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ae87648",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ab_classifier, open('Resources/ab_classifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a9470",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e7b9ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END ....C=1.0, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1.0, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1.0, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1.0, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1.0, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=1.0, max_iter=1000, penalty=l2;, score=0.895 total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=1.0, max_iter=1000, penalty=l2;, score=0.895 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=1.0, max_iter=1000, penalty=l2;, score=0.895 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=1.0, max_iter=1000, penalty=l2;, score=0.895 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=1.0, max_iter=1000, penalty=l2;, score=0.895 total time=   2.3s\n",
      "[CV 1/5] END ....C=1.0, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1.0, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1.0, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1.0, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1.0, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=1.0, max_iter=1500, penalty=l2;, score=0.895 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=1.0, max_iter=1500, penalty=l2;, score=0.895 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=1.0, max_iter=1500, penalty=l2;, score=0.895 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=1.0, max_iter=1500, penalty=l2;, score=0.895 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=1.0, max_iter=1500, penalty=l2;, score=0.895 total time=   3.6s\n",
      "[CV 1/5] END ....C=1.0, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1.0, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1.0, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1.0, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1.0, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=1.0, max_iter=2000, penalty=l2;, score=0.895 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=1.0, max_iter=2000, penalty=l2;, score=0.895 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=1.0, max_iter=2000, penalty=l2;, score=0.895 total time=   4.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=1.0, max_iter=2000, penalty=l2;, score=0.895 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=1.0, max_iter=2000, penalty=l2;, score=0.895 total time=   4.5s\n",
      "[CV 1/5] END ....C=0.1, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.1, max_iter=1000, penalty=l2;, score=0.895 total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.1, max_iter=1000, penalty=l2;, score=0.895 total time=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.1, max_iter=1000, penalty=l2;, score=0.895 total time=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.1, max_iter=1000, penalty=l2;, score=0.895 total time=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.1, max_iter=1000, penalty=l2;, score=0.895 total time=   2.4s\n",
      "[CV 1/5] END ....C=0.1, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.1, max_iter=1500, penalty=l2;, score=0.895 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.1, max_iter=1500, penalty=l2;, score=0.895 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.1, max_iter=1500, penalty=l2;, score=0.895 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.1, max_iter=1500, penalty=l2;, score=0.895 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.1, max_iter=1500, penalty=l2;, score=0.895 total time=   3.6s\n",
      "[CV 1/5] END ....C=0.1, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.1, max_iter=2000, penalty=l2;, score=0.895 total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.1, max_iter=2000, penalty=l2;, score=0.895 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.1, max_iter=2000, penalty=l2;, score=0.895 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.1, max_iter=2000, penalty=l2;, score=0.895 total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.1, max_iter=2000, penalty=l2;, score=0.895 total time=   5.1s\n",
      "[CV 1/5] END ...C=0.01, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, max_iter=1000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 2/5] END .C=0.01, max_iter=1000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 3/5] END .C=0.01, max_iter=1000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 4/5] END .C=0.01, max_iter=1000, penalty=l2;, score=0.895 total time=   0.4s\n",
      "[CV 5/5] END .C=0.01, max_iter=1000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END ...C=0.01, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, max_iter=1500, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 2/5] END .C=0.01, max_iter=1500, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 3/5] END .C=0.01, max_iter=1500, penalty=l2;, score=0.895 total time=   0.8s\n",
      "[CV 4/5] END .C=0.01, max_iter=1500, penalty=l2;, score=0.895 total time=   0.4s\n",
      "[CV 5/5] END .C=0.01, max_iter=1500, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END ...C=0.01, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.01, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.01, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.01, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.01, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, max_iter=2000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 2/5] END .C=0.01, max_iter=2000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 3/5] END .C=0.01, max_iter=2000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 4/5] END .C=0.01, max_iter=2000, penalty=l2;, score=0.895 total time=   0.4s\n",
      "[CV 5/5] END .C=0.01, max_iter=2000, penalty=l2;, score=0.895 total time=   0.5s\n",
      "[CV 1/5] END ..C=0.001, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, max_iter=1000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=1000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, max_iter=1000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, max_iter=1000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, max_iter=1000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.001, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, max_iter=1500, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=1500, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=1500, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, max_iter=1500, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, max_iter=1500, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, max_iter=1500, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 1/5] END ..C=0.001, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, max_iter=2000, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, max_iter=2000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, max_iter=2000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, max_iter=2000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, max_iter=2000, penalty=l2;, score=0.895 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, max_iter=2000, penalty=l2;, score=0.895 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\", line 257, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1185, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\", line 1024, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.89522667        nan 0.89522667        nan 0.89522667\n",
      "        nan 0.89522667        nan 0.89522667        nan 0.89522667\n",
      "        nan 0.89522667        nan 0.89522667        nan 0.89522667\n",
      "        nan 0.89522667        nan 0.89522667        nan 0.89522667]\n",
      "  warnings.warn(\n",
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(),\n",
       "             param_grid={'C': [1.0, 0.1, 0.01, 0.001],\n",
       "                         'max_iter': [1000, 1500, 2000],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= LinearSVC()\n",
    "param_grid = {'C': [1.0, 0.1, 0.01, 0.001],\n",
    "              'penalty': ['l1', 'l2'], \n",
    "            'max_iter':[1000, 1500, 2000]}\n",
    "svc_grid_clf = GridSearchCV(model, param_grid, verbose=3)\n",
    "svc_grid_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "402967a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'max_iter': 1000, 'penalty': 'l2'}\n",
      "0.8952266666666666\n"
     ]
    }
   ],
   "source": [
    "print(svc_grid_clf.best_params_)\n",
    "print(svc_grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44929ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8951733333333334\n",
      "Testing Data Score: 0.89312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelraines/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "svc_best_params=svc_grid_clf.best_params_\n",
    "svc_classifier= LinearSVC(**svc_best_params).fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {svc_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {svc_classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59491c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svc_classifier, open('Resources/svc_classifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1698049b",
   "metadata": {},
   "source": [
    "#### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1de667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 0.993/0.819\n",
      "k: 3, Train/Test Score: 0.910/0.869\n",
      "k: 5, Train/Test Score: 0.901/0.885\n",
      "k: 7, Train/Test Score: 0.898/0.889\n",
      "k: 9, Train/Test Score: 0.897/0.891\n",
      "k: 11, Train/Test Score: 0.896/0.892\n",
      "k: 13, Train/Test Score: 0.896/0.892\n",
      "k: 15, Train/Test Score: 0.896/0.893\n",
      "k: 17, Train/Test Score: 0.896/0.893\n",
      "k: 19, Train/Test Score: 0.895/0.893\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEICAYAAABI7RO5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0BElEQVR4nO3deZwcVbn/8c+3e2aSTPZlEpLJjjEQIExgDEIwhk3CIgn8RMGrIC5cFFSuioC4oOgVQUQQBEEQVBTxEkLUSEAIxLBI9hUSQhLIJCEZsq+zPr8/qiap9PTMdGemp2d53q9Xv7rqVJ3qpzuTfvrUqTpHZoZzzjmXqli2A3DOOde6eOJwzjmXFk8czjnn0uKJwznnXFo8cTjnnEuLJw7nnHNpyVjikPSwpM2SltaxXZLulrRK0mJJJ0S2TZS0Itx2Q6S8l6TnJL0VPvfMVPzOOeeSU6bu45A0HtgN/N7Mjk2y/Vzgq8C5wEnAXWZ2kqQ4sBI4CygB5gCXmtlySbcBW83s1jCh9DSz6xuKpU+fPjZ06NCmemvOOdcuzJs3730zK0gsz8nUC5rZLElD69llEkFSMeA1ST0k9QeGAqvMbDWApMfDfZeHzxPC+o8CLwINJo6hQ4cyd+7cw3sjzjnXTkl6J1l5Nvs4CoF1kfWSsKyucoB+ZrYRIHzu2wxxOueci8hm4lCSMqunPL2DS1dKmitpbmlpadrBOeecSy6biaMEGBRZHwhsqKccYFN4OovweXNdBzezB8ys2MyKCwpqnaJzzjl3mLKZOKYBl4VXV30Y2BGefpoDjJA0TFIecEm4b02dy8Ply4Gnmzto55xr7zLWOS7pzwQd2X0klQA/AHIBzOx+YDrBFVWrgL3AFeG2SknXADOAOPCwmS0LD3sr8ISkLwDvAhdnKn7nnHPJZexy3JakuLjY0r2qauqC9dw+YwUbtu9jQI9OXHf2SCaPKWy4onPOtRGS5plZcWJ5xlocrdnUBeu5ccoS9lVUAbB++z5unLIEwJOHc67d8yFHkrh9xooDSaPGvooqbp+xIksROedcy+GJI4kN2/elVe6cc+2JJ44kBvTolFa5c861J544krju7JF0yo0fUtYpN851Z4/MUkTOOddyeOd4EjUd4LfPWMH68PTUt87+oHeMO+ccnjjqNHlMIZPHFFKybS+n/mwm+8qrGq7knHPtgJ+qasDAnvmMHdqLqQs30B7ueXHOuYZ44kjBpDEDWLV5N8s27Mx2KM45l3WeOFJw3nH9yY2Lpxeuz3YozjmXdZ44UtAjP48JI/sybdEGqqr9dJVzrn3zxJGiyUWFbNpZxmurt2Q7FOecyypPHCk64+i+dOmQw9QFfrrKOde+eeJIUcfcOBOPPYJnlr7H/gq/NNc513554kjD5KJCdpVV8sKbdU486JxzbZ4njjScfGRv+nbt4KernHPtmieONMRj4oLjBzBzxWa27y3PdjjOOZcVnjjSNHlMIRVVxvQl72U7FOecywpPHGk6ZkA3jizozFS/GdA510554kiTJCYXFfL6mq0HRs51zrn2JKOJQ9JESSskrZJ0Q5LtPSU9JWmxpNclHRuWj5S0MPLYKenacNvNktZHtp2byfeQzKSiYHj1aQs3NPdLO+dc1mUscUiKA/cC5wCjgEsljUrY7TvAQjMbDVwG3AVgZivMrMjMioATgb3AU5F6d9ZsN7PpmXoPdRncO58Th/T0q6ucc+1SJlscY4FVZrbazMqBx4FJCfuMAp4HMLM3gaGS+iXscwbwtpm9k8FY0za5aAArNu3ijY0+Yq5zrn3JZOIoBNZF1kvCsqhFwEUAksYCQ4CBCftcAvw5oeya8PTWw5J6JntxSVdKmitpbmlp6eG+hzqdN3oAOTF5J7lzrt3JZOJQkrLEoWVvBXpKWgh8FVgAVB44gJQHXAD8NVLnPuBIoAjYCNyR7MXN7AEzKzaz4oKCgsN8C3Xr1TmP8R8s4G8LN1DtI+Y659qRTCaOEmBQZH0gcEhvspntNLMrwr6My4ACYE1kl3OA+Wa2KVJnk5lVmVk18CDBKbGsmDymkA079vP62q3ZCsE555pdJhPHHGCEpGFhy+ESYFp0B0k9wm0AXwRmmVm00+BSEk5TSeofWb0QWNrkkaforKP70Tkv7p3kzrl2JWOJw8wqgWuAGcAbwBNmtkzSVZKuCnc7Glgm6U2C1sXXa+pLygfOAqYkHPo2SUskLQZOA/4nU++hIZ3y4px9zBFMX7KRskofMdc51z7kZPLg4aWy0xPK7o8svwqMqKPuXqB3kvLPNnGYjTJpTCFTFqxn5pulTDz2iGyH45xzGed3jjfSuCN706dLns9H7pxrNzxxNFJOPMbHjx/A829uZse+imyH45xzGeeJowlMLiqkvLKaZ5ZuzHYozjmXcZ44msDogd0Z1qczUxf42FXOubbPE0cTkMSkogG8tmYL7+3Yn+1wnHMuozxxNJHJRYWYwbRF3knunGvbPHE0kaF9OlM0qIefrnLOtXmeOJrQ5KIBLN+4k5WbdmU7FOecyxhPHE3o/OMHEI/JhyBxzrVpnjiaUJ8uHTj1A3142kfMdc61YZ44mtjkMQNYv30f897dlu1QnHMuIzxxNLGPjTqCTrk+Yq5zru3yxNHEOnfI4WPH9OMfSzZSXlmd7XCcc67JeeLIgMlFhWzfW8FLK5t+ylrnnMs2TxwZcOqIPvTqnOfzkTvn2iRPHBmQG49x/uj+/Gv5Jnbt9xFznXNtiyeODJk8ppCyympmLNvU8M7OOdeKNJg4JOVL+p6kB8P1EZLOz3xorduYQT0Y0jvfr65yzrU5qbQ4fgeUASeH6yXAjzMWURshiUnHD+CVt99n804fMdc513akkjiONLPbgAoAM9sHKJWDS5ooaYWkVZJuSLK9p6SnJC2W9LqkYyPb1kpaImmhpLmR8l6SnpP0VvjcM5VYsmHSmEKqDaYt8oEPnXNtRyqJo1xSJ8AAJB1J0AKpl6Q4cC9wDjAKuFTSqITdvgMsNLPRwGXAXQnbTzOzIjMrjpTdADxvZiOA58P1FunIgi4cV9idpxd64nDOtR2pJI4fAM8AgyQ9RvBl/e0U6o0FVpnZajMrBx4HJiXsMyo8Hmb2JjBUUr8GjjsJeDRcfhSYnEIsWTN5TCFL1u9g1ebd2Q7FOeeaRL2JQ1IM6AlcBHwO+DNQbGYvpnDsQmBdZL0kLItaFB4bSWOBIcDAcJsBz0qaJ+nKSJ1+ZrYRIHzuW0fsV0qaK2luaWn2bsT7+PH9iQme9ns6nHNtRL2Jw8yqgWvMbIuZ/cPM/m5m76d47GT9IIlDxt4K9JS0EPgqsACoDLeNM7MTCE51XS1pfIqvWxP7A2ZWbGbFBQUF6VRtUn27dmRcOGKumY+Y65xr/VI5VfWcpG9JGhR2TPeS1CuFeiXAoMj6QOCQk/1mttPMrjCzIoI+jgJgTbhtQ/i8GXiK4NQXwCZJ/QHC580pxJJVk4oKeXfrXua/uz3boTjnXKOlkjg+D1wNzALmhY+59dYIzAFGSBomKQ+4BJgW3UFSj3AbwBeBWWa2U1JnSV3DfToDHwOWhvtNAy4Ply8Hnk4hlqw6+5h+dMiJ+ekq51ybkNPQDmY27HAObGaVkq4BZgBx4GEzWybpqnD7/cDRwO8lVQHLgS+E1fsBT0mqifFPZvZMuO1W4AlJXwDeBS4+nPiaU9eOuZw1qh9/X7yR750/ity437DvnGu9GkwcknKBLwM1fQwvAr8xswYHYTKz6cD0hLL7I8uvAiOS1FsNHF/HMbcAZzT02i3N5KJC/r54I/9+q5TTj2rowjHnnGu5Uvnpex9wIvDr8HFiWObSMP6DBfTIz2XqAr+nwznXujXY4gA+ZGbRX/8vSFqUqYDaqrycGOcd158p89ezp6ySzh1S+eidc67lSaXFURXeLQ6ApOFAVeZCarsuHFPIvooqnl3+XrZDcc65w5ZK4rgOmCnpRUkvAS8A38xsWG3TiUN6MrBnJ57y01XOuVYslauqnpc0AhhJcFPfm2bW4FhVrjZJTCoawH0vvk3prjIKunbIdkjOOZe2VObjuBroZGaLzWwRkC/pK5kPrW2aXBSMmPv3xd7qcM61TqmcqvqSmW2vWTGzbcCXMhZRGzeiX1dG9e/GVB8x1znXSqWSOGIK78SDA8Ol59Wzv2vAhWMKWbRuO2ve35PtUJxzLm2pJI4ZBHdqnyHpdIIRcp9poI6rx8ePH4CETyvrnGuVUkkc1xPMmfFlgjGrUp2Pw9XhiO4dOXl4b55euN5HzHXOtToNJg4zqw6HCfk0wVzjT5mZ38fRSJOLClm7ZS+LSnZkOxTnnEtLnYlD0v2SjgmXuwMLgd8DCyRd2jzhtV0TjzuCvJyYn65yzrU69bU4PmJmy8LlK4CVZnYcwVhVfqqqkbp1zOXMo/vy98UbqKyqznY4zjmXsvoSR3lk+SxgKoCZ+XgZTWRSUSHv7y5n9qpUJ1V0zrnsqy9xbJd0vqQxwDjCK6kk5QCdmiO4tm7CyAK6dczhab+nwznXitQ35Mh/A3cDRwDXRloaZwD/yHRg7UGHnDjnje7P0ws3sLe8kvw8HzHXOdfy1dniMLOVZjbRzIrM7JFI+Qwz80EOm8ikokL2llfx3PJN2Q7FOedS4nOYZtnYob0Y0L2jn65yzrUanjiyLBYTFxQV8tLKUrbs9kGHnXMtXyqj48YP9+CSJkpaIWmVpBuSbO8p6SlJiyW9LunYsHyQpJmS3pC0TNLXI3VulrRe0sLwce7hxtdSTB4zgKpq4x9LNmY7FOeca1AqLY5Vkm6XNCqdA4cJ517gHGAUcGmSY3wHWGhmo4HLgLvC8krgm2Z2NPBh4OqEuneGfS9FZjY9nbhaoqOO6MZRR3T1mwGdc61CKoljNLAS+K2k1yRdKalbCvXGAqvMbLWZlQOPA5MS9hlFMPYVZvYmMFRSPzPbaGbzw/JdwBtAYWpvqXWaVFTI/He38+6WvdkOxTnn6pXKWFW7zOxBMzuF4I7xHwAbJT0q6QP1VC0E1kXWS6j95b8IuAhA0lhgCDAwuoOkocAY4D+R4mvC01sPS+rZ0HtoDSYVDQDg6YXe6nDOtWwp9XFIukDSUwSnku4AhgN/A+o7TaQkZYlDwd4K9JS0EPgqsIDgNFXNa3cBniS4j2RnWHwfcCRQBGwM40kW95WS5kqaW1paWu97bAkG9OjEScN68ZSPmOuca+FSOVX1FsEpptvNbIyZ/cLMNpnZ/1H/vBwlwKDI+kDgkGtOzWynmV1hZkUEfRwFwBoASbkESeMxM5sSqbPJzKrMrBp4kOCUWC1m9oCZFZtZcUFBQQpvM/smjylkdekelq7f2fDOzjmXJSn1cZjZF8zslcQNZva1eurNAUZIGiYpD7gEmBbdQVKPcBvAF4FZZrYznHHwIeANM/tFQp3+kdULgaUpvIdW4dxj+5MXjzHVT1c551qwVBLHvZJ61KyEl9A+3FAlM6sEriGYQfAN4AkzWybpKklXhbsdDSyT9CbB1Vc1l92OAz4LnJ7kstvbJC2RtBg4DfifFN5Dq9A9P5cJIwv426INVFX76SrnXMuUyuBIo81se82KmW0LBz5sUHip7PSEsvsjy68CI5LUm03yPhLM7LOpvHZrdeGYQp5dvolX397CqSP6ZDsc55yrJZUWRyx65ZKkXqSWcNxhOO2ovnTtmMNTfk+Hc66FSiVx3AG8IukWSbcArwC3ZTas9qtjbpxzjj2CGcveY3+Fz9DrnGt5UrmP4/fAJ4BNwGbgIjP7Q6YDa88mFxWyu6ySf73hI+Y651qelAY5DKeQfQJ4GtgtaXBGo2rnThrem37dOjB1gY+Y65xreVK5AfACSW8R3F/xErAW+GeG42rX4jExqaiQl1ZuZtue8oYrOOdcM0qlxXELwUCDK81sGMEMgC9nNCrHpKIBVFT5iLnOuZYnlcRRYWZbCK6uipnZTILhPlwGjerfjRF9u/jYVc65FieVxLE9HDNqFvCYpLuIjCflMkMSk8cUMmftNkq2+Yi5zrmWI5XEMQnYS3CH9jPA28DHMxmUC1xwfM2Iud5J7pxrOeq9kS+cjOlpMzsTqAYebZaoHACDeuUzrE8+dz63kp/PWMGAHp247uyRTB7Tpqcmcc61cPW2OMysCtgrqXszxeMipi5YT8m2fVRWGwas376PG6cs8ZkCnXNZlcrQIfuBJZKeA/bUFDYwMq5rArfPWEFF1aGDHe6rqOL2GSu81eGcy5pUEsc/wodrZhu270tavn77PqYv2ci4D/She6fcZo7KOdfeNZg4zMz7NbJkQI9OrE+SPAR85bH5xGPihME9mDCyLx/9YAGj+ncjFks6qLBzzjUZNTRNqaQ11J7yFTMbnqmgmlpxcbHNnTs322GkbeqC9dw4ZQn7IoMddsqN85PJxzC4d2deXFHKiys3H5gxsE+XDnz0gwVMGFnAR0b0oUd+Xl2Hds65BkmaZ2bFieWpnKqKVuoIXAz0aqrAXN1q+jFun7GCDdv31bqqqnhoL7519khKd5Uxa2UpL64s5fk3N/Hk/BJigqJBQWtkwsgCjh3Q3Vsjzrkm0WCLI2klabaZnZqBeDKitbY4DkdVtbGoZDsvrijlpRWbWbx+B2bQu3Me4w+0Rgro1dlbI865+h12i0PSCZHVGEELpGsTxuaaUNDv0ZMTBvfkG2d9kC27y5j1VikvrSjlpZWlPLVgPRKMHtiDCWEiGT2wB3FvjTjnUpRKH8fMyGolwSi5d5jZikwG1pTaU4ujPlXVxpL1O3hxxWZeWlnKwnXbMYOe+bl8ZESQRMZ/sIA+XTpkO1TnXAtQV4vjsE5VtTaeOJLbtqf8QGtk1lulvL87GMJ99MDuBzrZiwb1JB4TUxesr7OvxTnXNh124pD0v8BtZrY9XO8JfNPMvpvCi04E7gLiwG/N7NaE7T2Bh4EjCW40/LyZLa2vbjjn+V+AoQRzg3zSzLbVF4cnjoZVVxvLNuw80BqZ/+42qg26d8plWJ98lm3YecjNiJ1y4/z0ouM8eTjXhjUmcSwwszEJZfPN7IS66oT7xIGVwFlACTAHuNTMlkf2uR3YbWY/lHQUcK+ZnVFfXUm3AVvN7FZJNwA9zez6+mLxxJG+HXsr+PeqUl5cUcqU+SVUJ/kz6ZQb53PjhtK3awcKunagb9eO4XMHOndI5YI951xL1pjLceOSOphZWXigTkAqJ8HHAqvMbHVY73GCkXaXR/YZBfwUwMzelDRUUj9geD11JwETwvqPAi8C9SYOl77u+bmcP3oA548ewJPzSpLus6+iigdnraYySVbJz4vXSig1SSVa1rtzXlqXCfspM+eyL5XE8UfgeUm/I7gR8POkNkpuIbAusl4CnJSwzyLgImC2pLHAEGBgA3X7mdlGADPbKKlvsheXdCVwJcDgwT5FemPUdQd7YY9O/Pvbp7F9XwWbd+1n884ySneVsXlXzfN+SneV8cbGncxaWcaustrTuMRjonfnPPp260BBlyCh9O2WPMk8s/S9Q26IrBn0EfDk4VwzSmXIkdskLQbOJBjt4hYzm5HCsZP9jEz8aXorcJekhcASYAHBlVup1K2XmT0APADBqap06rpDXXf2yKR3sF939khiMdGrcx69Oudx1BH1H2dveSWlu5Inl83hY+mGnWzZXZb01Jio/Uewr6KKm6Yu4e3S3XTKi9M5L+fAc35ePHyEZR3i5OfmkN8hTm48lalokmsprZ6WEodrf1K5j2MY8KKZPROud5I01MzWNlC1BBgUWR8IHDIjkZntBK4IjyuCS33XAPn11N0kqX/Y2ugPbG7oPbjGaegO9lTl5+UwpHcOQ3p3rne/qmpjy56yoAWzu4zS8Pn2GcmvAN9TVsU9M1eRzgWCuXGRn5BcDix3yCE/N07nDjVJKE6nvBw658VZtmEHf5lTQnlVNRC0eq5/cjFb9pRx/ugB5MVj5OUEj5yYCP6sm17icDTZbH21lATmcTRfHKl0js8FTjGz8nA9D3jZzD7UQL0cgg7uM4D1BB3cnzazZZF9egB7zaxc0peAj5jZZfXVDTvUt0Q6x3uZ2bfri8U7x9uGcbe+UOcps9nXn8b+imr2lleyt7yKveVV7CmvZF95FXvKKtlXEZaVhWXlVewrrwyfg32DeuFz2cHlZH04qZAgLx6jQ06MvJx4+Bw7JLnUWRavWY4fKI/u89Ppb7Btb0Wt1+zdOY+7Lx1zsMkuULgmHWzKS0pYD3dOtl9kn+ixAGau2Mw9L6yirLL6QAwdcmJ862MjmXjsEcRjIh4TMQXPcYl4PHiOxQjWmyDB1jWuW3Nf+dfW4mjMVVULzawooWyRmR2fwoueC/yS4JLah83sJ5KuAjCz+yWdDPweqCLo+P5CzaW1yeqG5b2BJ4DBwLvAxWa2tb44PHG0Ddn6T1leWX0guYy79YU6z5n+5MJjKa+sPvAoq6ymvCqyfGC9KklZsjrBfoeZt1qVmDg0wcQOJppYTOQkbIsJcmIxYjERj8GK93bVmrsGgiRWPLQnsTAxxSIJs2YZguPVJMZYLEyQCvcJ46tJokpyDIXbpy5Yz97yqlpxdOkQ579OGoIUxBvUC143Jh04fixSpvC55v3WtT2WcLy4xE1Tl7J1T3mtOAp7dOLlG05P+d+lMVdVlUq6wMymhQeaBLyfyoua2XRgekLZ/ZHlV4ERqdYNy7cQtERcO9NUp8zSVfMrv3t+br0XCvzXSUMy8vqVVbWTy/+77xU27yqrtW+fLnnc++ngSnmDA6fvDDvQQVRTbmGBHdyEmR1MjIn7HFI/WLnyD/PqjPv2T4ym2ozKaqO62qiqNqoMqqqrqaqGagvLDmw7uF9ltR3YXvN84DgW3HdUGTnOuPceY3FsOK9WH3Pg9U+OLWO0rWZuxWWYGdV2MPaa919dXbvMLDimhW+2Zrm6Zh87+DlF9zWDz1ZNTR5H5WoeeWXSgf2rw3gy5b/jf0sax/G7VgOpJ466pJI4rgIek3QPQZJdB1zW6Fd27jBMHlOY1Q7g+i4UyJSceIyceIzoKPnfOffopHF897xRnDS8d8ZiSXRdl2eYvXdQrS+oU/PXcXHxec0Wx1d/8gr3lN/ONRVf49XqYzg5tox7cu/m5rzrePLLpzRjHMvqjGPFTefU2r8modUkk4OJJejrq297dbUlJKKD+9714EruqbwjaRxNIeUhRyR1Cfff1SSv3Iz8VJVrMrN/yey9g7l+fo8DrZ6fnbCdU/PfhVOvbXdxzH52CqNe/hpXR76g7s29m+Xj7ubUj110eAc1g6oKqK6AqnKoqgyeqyuC8qqwvDosr6rglZUb+c/LL/DF2DT+XX0cH4kt5o92Dh8qPoniwT3Aqg/zYcnLq6uSbl9duou1q1dyipawygbwAW3gdTuGIUOHM6RXPkEz7kD7roFlO/h5pLR88Hnjjr1s3LieY1nNk1Wn8rH4PL5RfS0XXnRp8/RxhJXPA44hmI8jjM9+lPKrZ5knDtdk1syCv34OLn4Eho2vvd4czGD1S/Dk52Hy/TBoLKydDdOugfN+AYUnBl+q1VXBl211ZWS98uCjqvLQ9UO2V9Tev2afqkOPueGdlfR+bxarqgcwIraBHX3GUNCn7yFf7A0ngsj26tr3+7QIiiU84pFlHVjeX2VUl+0hn/3soSOxjt3plFdzcifsEKm55CByUcKh5UmWD1xA0NBysL59fwWVO96jD9v5Xfxiep7/w7Rb643pHL+f4PLY04DfAp8AXjezL6QVQRZ54nCNUl0Fe7fAntLgsWY2vPZr6D8aNiyEkROha/9aX6i1v5Sb8Es8mxSDWA7EcsPnOFTuh4q90KE7dOkL8dzgEcuFeB7Ec4LnWO7BbfG8oH48L43966m/aSn864dw7EWwdApMvDVIqrW+8BMesQa21ySGVNX8mCj+Asx9qHl/VDRxHI3pHD/FzEZLWhyOKXUHMCWtV3euKcz+JRSecOgf/5pZsH5+eqdnzKBsV5gI3j+YEA5Zjqzv3ULS+0/ffTX41bny2YNfoLGcyCMefhkm25YDuZ0iX8BJtkfL4sn2iQctjzUvwZFnwlHnJq9fXwyxeCQBJNknnrC/4sEXbVTNF9TJ1wRfUOf/ovm/KNfMghd+DJ/6Q/Dax1zY/C3BmjiirzvsI20yjlQSR80lJHslDQC2AMMa/crOpavwhLpPE1WWRb7460gA0eWq2lckAdCxB3QuCB59RsCQU8L1PgfLt70Dz94U/JKb93B2f1G+ei+M/3bwhX3q17Pzhd0SvijXzz/0NYeND9bXz/c4MhBHKqeqvgf8iuAS2HsJfno9aGbfb/SrNxM/VdXKle2GbWth2xpY9Tws+jN0HxSsd+4L5XugbEfyuvEOwamT6Bd/reW+wXJ+b8hpYErdltDH0ZLiaKpWoGuRmmQiJ0kdgI5mVsf/0pbJE0cLZxacDtq6GrauCRJC9HlPwqgyOR2Dc+o9BsPADyVJBpH1vC7pnZ9uSEv5omwpcbg2zWcA9MSRXdVVsKOkdlLYtga2roXy6FXegm6F0GsY9BwaPg+DXsNh10Z4+ursdzw61w40pnPctXep/rqt2H/wlFJictj2TnB1UI14HvQYEiSFwacEz72GBwmix2DI7Ugta2YFSSPb59Oda+c8cbiGRTuljzguuNTxue8HV648fXWQHLaugV0bDq3XoVvQYuh3DBx1/qHJoduA4AqedLSUjkfn2rlUOseTTRG7A3jHzFronTqH8lNVjVRVCc/fHFzBY9WHbuvSLzyNFDmdVLOc36tp+xecc82qMaeqfg2cACwmuCXx2HC5t6SrzOzZJo3UtRzVVUHr4sX/DTquuxwBu9+DURfCR68LWhN59c+t4Zxre1KZBm0tMMbMis3sRGAMsJRgRsDbMhibyxYzWD4N7hsHU74Iuflw2neDPorx34a1s4KroDxpONcupdLiOCo6+ZKZLZc0xsxWZ2p2M5clZvDWczDzx7BxEfQeAZ94GDr1gSev8E5p5xyQWuJYIek+4PFw/VPAyvCejtpTkLnWqWbIhnX/Ca5qmnwfHPfJYMiJ2b/0Tmnn3AGpdI53Ar4CnErQxzGboN9jP5BvZrszHWRjeed4Pda9Di/cEiSOrgOCvouizzR8B7Vzrs077M5xM9sH3BE+ErX4pOHqsGEhzPwJvPVscIf12T+F4s8nv3/COeciGkwcksYBNwNDovub2fDMheUyZvMbMPN/4Y1pwYB+Z/wAxl4JHbpkOzLnXCuRSh/HQ8D/APOA2rOw10PSROAuIA781sxuTdjeHfgjMDiM5edm9jtJI4G/RHYdDnzfzH4p6WbgS0BpuO074fzkrj5b3oYXb4Ulfw3Gb/roDXDyV6Bj92xH5pxrZVJJHDvM7J/pHlhSnGA03bOAEmCOpGlmtjyy29XAcjP7uKQCgo74x8xsBVAUOc564KlIvTvN7OfpxtQubV8Hs26DBY8Fw3yM+xqc8nXo3HzzUjvn2pZUEsdMSbcTTN50YBIDM5vfQL2xwCozWw0g6XFgEhBNHAZ0VXBdbxdgK5B4N/oZwNtm9k4Ksboau96Df98B8x4J1sd+CU79BnTtl9WwnHOtXyqJ46TwOdqzbsDpDdQrBNZF1ksix6pxDzAN2AB0BT5lljimBZcAf04ou0bSZcBc4Jtmtq2BWNqPPVvg5Tvh9QeDKUbHfAbGXwfdB2Y7MudcG5HKVVWnHeaxk90dmHjt79nAQoIkdCTwnKR/m9lOAEl5wAXAjZE69wG3hMe6heBqr8/XenHpSuBKgMGDBx/mW2hF9m0PxpJ67dfBxEajPwUTrg/GjnLOuSZUZ+KQ9Bkz+6OkbyTbbma/aODYJcCgyPpAgpZF1BXArRbcTLJK0hrgKOD1cPs5wHwz2xR53QPLkh4E/l5HfA8AD0BwH0cDsbZeZbvhP/fDK3fD/h0wajJMuBH6HpXtyJxzbVR9LY6agYi6JtmWyhfxHGCEpGEEnduXAJ9O2Oddgj6Mf0vqB4wEVke2X0rCaSpJ/c1sY7h6IcG4We1PxT6Y8xDMvhP2vg8fnAinfQf6H5/tyJxzbVydicPMfhMu/svMXo5uC+/tqJeZVUq6BphBcDnuw2a2TNJV4fb7CU41PSJpCcGprevN7P3wNfIJrsj674RD3yapiCB5rU2yve1INoHSqhdg7m+D4T52bYThE4IBCAd9KFtROufamVSGHJlvZic0VNaStdohR9bMOjiY4OBT4Pkfwau/CubEGPRhOP27wYCDzjmXAWkPOSLpZOAUoCChn6MbQQvCZVrNYIKP/1cwW96+bdD7A3DOz+DIM3ySJOdcVtTXx5FHcG9FDof2c+wEPpHJoFxEnw8Gc3lXlwcTKF38O08Yzrmsqq+P4yXgJUmP1Nx8JykGdKm5XNY1g6euCpLGh74Ey6bA2n/7UObOuaxKZQbAn0rqJqkzwV3fKyRdl+G4HMBr98PqmcG8GOf9PDht9dfPBX0fzjmXJakkjlFhC2MyMJ1gQMLPZjIoB1RVwuxfQH4f+Pgvg7LoBErOOZclqQw5kisplyBx3GNmFZLa7g11LcXch2D3Jvjk7w+d23vYeD9V5ZzLqlRaHL8huF+iMzBL0hCCDnKXKbs3wws/geGnwdEXZDsa55w7RCpjVd0N3B0pekfS4Y5f5VLxrx9CxV4493a/gso51+I02OKQ1E/SQ5L+Ga6PAi7PeGTt1brXYeEf4eSroc+IbEfjnHO1pHKq6hGCYUMGhOsrgWszFE/7Vl0F078FXQcEQ6E751wLVGfikFRzGquPmT0BVEMwBhVpTiHrUjTvd7BxEZz9Y58D3DnXYtXX4qgZ2nyPpN6EI+JK+jCwI9OBtTt7tsDztwRXTB1zUbajcc65OtXXOV7TK/sNgln6jpT0MlCADznS9J7/IZTvhnO8Q9w517LVlziigxs+RXDznwjmHT8TWJzh2NqP9fNg/u+DDnGfgMk518LVlzjiBIMcJv78zc9cOO1QdTX841vQpS989PpsR+Occw2qL3FsNLMfNVsk7dWC38OG+XDRg9CxW7ajcc65BtXXOe4n2jNt79bgZr8h4+C4i7MdjXPOpaS+xHFGs0XRXr3wY9i/A865zTvEnXOtRp2Jw8y2Nmcg7c6GhTD3YRj7JTji2GxH45xzKUvlznHX1KqrgzvEO/eBCTdmOxrnnEtLRhOHpImSVkhaJemGJNu7S/qbpEWSlkm6IrJtraQlkhZKmhsp7yXpOUlvhc89M/keMmLRn6BkDpz1I+jUI9vROOdcWjKWOCTFgXuBc4BRwKXhAIlRVwPLzex4YAJwh6S8yPbTzKzIzIojZTcAz5vZCOD5cL312LcdnvsBDDoJRl+S7Wiccy5tmWxxjAVWmdlqMysHHgcmJexjQFdJIrhnZCtQ2cBxJwGPhsuPEkww1XrM/F/YtzUYMj3mZwqdc61PJr+5CoF1kfWSsCzqHuBoYAOwBPi6mVWH2wx4VtI8SVdG6vQzs40A4XPfZC8u6UpJcyXNLS0tbfy7aQrvLYE5D0Lx56H/8dmOxjnnDksmE0ey60sTp5w9G1hIMGR7EXCPpJq74MaZ2QkEp7qulpTWfKlm9oCZFZtZcUFBQVqBZ4QZTL8OOvWE07+b7Wicc+6wZTJxlACDIusDCVoWUVcAUyywClgDHAVgZhvC580EY2WNDetsktQfIHzenLF30JQWPwHvvgpn3hwkD+eca6UymTjmACMkDQs7vC8hGGU36l3CGw0l9QNGAqsldZbUNSzvDHwMWBrWmcbBGQgvB57O4HtoGvt3wnPfg8IToegz2Y7GOecapcE5xw+XmVVKuoZg9sA48LCZLZN0Vbj9fuAW4BFJSwhObV1vZu9LGg48FfSZkwP8ycyeCQ99K/CEpC8QJJ6WP1bHi7fC7s1w6ePeIe6ca/UyljgAzGw6wXDs0bL7I8sbCFoTifVWA0l7j81sC61pOJRNy+E/98OJl0PhCdmOxjnnGs1//mZSTYd4x25wxg+yHY1zzjWJjLY42r2lT8I7s+H8OyG/V7ajcc65JuEtjkwp2wXPfje4X+OEyxve3znnWglvcWTKS7fBro3wyT9ALJ7taJxzrsl4iyMTSlfAa7+GMZ+BQR/KdjTOOdekPHE0tZoO8bzOcOYPsx2Nc841OU8cTW3507DmJTjtu8F8G84518Z44mhK5Xtgxk3Q77hgIEPnnGuDvHO8Kc36OewsgU88BHH/aJ1zbZO3OJrK+6vglV/B8ZfC4A9nOxrnnMsYTxxNwQz++W3I7eQd4s65Ns8TR1N48x/w9vMw4Ubo2i/b0TjnXEZ54mis8r3wzI3QdxSMvbLh/Z1zrpXzHtzGmn0n7HgXPjfdO8Sdc+2CtzgaY+tqePkuOO5iGDou29E451yz8MTRGM/cCPFcOOuWbEfinHPNxhPH4VrxDKx8Bj56PXTrn+1onHOu2XjiOBwV++GZ66HPSPjwl7MdjXPONSvvzT0cL98F29bCZU8Hp6qcc64dyWiLQ9JESSskrZJ0Q5Lt3SX9TdIiScskXRGWD5I0U9IbYfnXI3VulrRe0sLwcW4m30Mt29bC7F/AqMkwfEKzvrRzzrUEGWtxSIoD9wJnASXAHEnTzGx5ZLergeVm9nFJBcAKSY8BlcA3zWy+pK7APEnPRereaWY/z1Ts9ZpxEygGZ/8kKy/vnHPZlskWx1hglZmtNrNy4HFgUsI+BnSVJKALsBWoNLONZjYfwMx2AW8AhRmMNTVv/Qve/DuMvw66D8x2NM45lxWZTByFwLrIegm1v/zvAY4GNgBLgK+bWXV0B0lDgTHAfyLF10haLOlhST2bOvCkKsvgn9dB7w/AyVc3y0s651xLlMnEoSRllrB+NrAQGAAUAfdI6nbgAFIX4EngWjPbGRbfBxwZ7r8RuCPpi0tXSporaW5paenhv4sar/wquOHvnJ9BTofGH88551qpTCaOEmBQZH0gQcsi6gpgigVWAWuAowAk5RIkjcfMbEpNBTPbZGZVYcvkQYJTYrWY2QNmVmxmxQUFBY17J9vXBXNtHHU+fODMxh3LOedauUwmjjnACEnDJOUBlwDTEvZ5FzgDQFI/YCSwOuzzeAh4w8x+Ea0gKXq33YXA0gzFf9CzNwXPE3+a8ZdyzrmWLmOJw8wqgWuAGQSd20+Y2TJJV0m6KtztFuAUSUuA54Hrzex9YBzwWeD0JJfd3iZpiaTFwGnA/zR58LN/CWtmBctvzwzmET/2/8HSKfVWc8659kBmid0ObU9xcbHNnTs39QprZsFfPwcX/TaYoKlsF1RXwMWPwLDxmQrTOedaFEnzzKw4sdzvHE9m2PggSfzpU1CxFzp0hUv+5EnDOefwsarqNmw8DD8tWD7py540nHMu5ImjLmtmwbrXYPy3Ye5DB/s8nHOunfPEkUxNH8fFj8DpNwXPf/2cJw/nnMMTR3Lr5x/aEV7T57F+fjajcs65FsE7x5M59draZcPGez+Hc87hLQ7nnHNp8sThnHMuLZ44nHPOpcUTh3POubR44nDOOZeWdjFWlaRS4J1sx9GAPsD72Q4iBR5n02otcULridXjbDpDzKzWvBTtInG0BpLmJhtMrKXxOJtWa4kTWk+sHmfm+akq55xzafHE4ZxzLi2eOFqOB7IdQIo8zqbVWuKE1hOrx5lh3sfhnHMuLd7icM45lxZPHM1E0iBJMyW9IWmZpK8n2WeCpB2Reda/n41Yw1jWhnO7L5RUa95dBe6WtErSYkknZCHGkZHPaqGknZKuTdgnK5+ppIclbZa0NFLWS9Jzkt4Kn3vWUXeipBXhZ3tDlmK9XdKb4b/tU5J61FG33r+TZojzZknrI/++59ZRt9k+0zri/EskxrWSFtZRt9k+z0YxM380wwPoD5wQLncFVgKjEvaZAPw927GGsawF+tSz/Vzgn4CADwP/yXK8ceA9guvOs/6ZAuOBE4ClkbLbgBvC5RuAn9XxPt4GhgN5wKLEv5NmivVjQE64/LNksabyd9IMcd4MfCuFv41m+0yTxZmw/Q7g+9n+PBvz8BZHMzGzjWY2P1zeBbwBFGY3qkaZBPzeAq8BPST1z2I8ZwBvm1mLuNHTzGYBWxOKJwGPhsuPApOTVB0LrDKz1WZWDjwe1suYZLGa2bNmVhmuvgYMzGQMqajjM01Fs36m9cUpScAngT9n6vWbgyeOLJA0FBgD/CfJ5pMlLZL0T0nHNG9khzDgWUnzJF2ZZHshsC6yXkJ2E+El1P2fsaV8pv3MbCMEPySAvkn2aWmfK8DnCVqXyTT0d9IcrglPqT1cx+m/lvSZfgTYZGZv1bG9JXyeDfLE0cwkdQGeBK41s50Jm+cTnGo5HvgVMLWZw4saZ2YnAOcAV0tKnMVKSepk5RI9SXnABcBfk2xuSZ9pKlrM5wog6SagEnisjl0a+jvJtPuAI4EiYCPBaaBELekzvZT6WxvZ/jxT4omjGUnKJUgaj5nZlMTtZrbTzHaHy9OBXEl9mjnMmlg2hM+bgacImvtRJcCgyPpAYEPzRFfLOcB8M9uUuKElfabApprTeeHz5iT7tJjPVdLlwPnAf1l4Aj5RCn8nGWVmm8ysysyqgQfreP0W8ZlKygEuAv5S1z7Z/jxT5YmjmYTnNh8C3jCzX9SxzxHhfkgaS/Dvs6X5ojwQR2dJXWuWCTpKlybsNg24LLy66sPAjprTMFlQ56+4lvKZhqYBl4fLlwNPJ9lnDjBC0rCwJXVJWK9ZSZoIXA9cYGZ769gnlb+TjEroV7uwjtdvEZ8pcCbwppmVJNvYEj7PlGW7d769PIBTCZrHi4GF4eNc4CrgqnCfa4BlBFd9vAackqVYh4cxLArjuSksj8Yq4F6Cq1WWAMVZijWfIBF0j5Rl/TMlSGQbgQqCX7xfAHoDzwNvhc+9wn0HANMjdc8luOru7ZrPPguxriLoF6j5W70/Mda6/k6aOc4/hH9/iwmSQf9sf6bJ4gzLH6n5u4zsm7XPszEPv3PcOedcWvxUlXPOubR44nDOOZcWTxzOOefS4onDOedcWjxxOOecS4snDudCkoZGRzRtwuP+SNKZDexzs6RvNVdMzjVGTrYDcK6tM7NsDo8fN7OqbL2+a5u8xeFcEpKGS1og6UMJ5RMkvSjp/8L5Kh6L3Jl+oqSXwgHqZkSGF3lE0ifC5XPDerMVzGfy98jhR4XHXi3pa5HyHEmPhgP5/Z+k/PBYZ4QxLgkH+OsQlq+V9H1Js4GLJX1N0vKw/uMZ/NhcO+GJw7kEkkYSjCl2hZnNSbLLGOBaYBTB3b7jwnHIfgV8wsxOBB4GfpJw3I7Ab4BzzOxUoCDhuEcBZxOMT/SD8JgAI4EHzGw0sBP4SnisR4BPmdlxBGcPvhw51n4zO9XMHieY+2NMWP+qdD8P5xJ54nDuUAUEY0h9xswW1rHP62ZWYsHAeguBoQRf7scCz4Wzu32X2nNYHAWsNrM14Xri+Fr/MLMyM3ufYADEfmH5OjN7OVz+I8HwNSOBNWa2Mix/lGACoRrRgfQWA49J+gzBSLfONYr3cTh3qB0EYzSNIxgvKJmyyHIVwf8jAcvM7OR6jp1seO+Gjgu1hwC3FI61J7J8HkFSuQD4nqRj7OAkTc6lzVsczh2qnGBmvsskfTqNeiuAAkknQzCEfpJJo94EhocTeQF8KsVjD645LsFIwLPDYw2V9IGw/LPAS4kVJcWAQWY2E/g20APokuLrOpeUtzicS2BmeySdT3DaaY+ZJRv+PLFOedgBfrek7gT/t35JpNViZvskfQV4RtL7wOsphvQGcLmk3xCMrHufme2XdAXw13CehznA/UnqxoE/hjEJuNPMtqf4us4l5aPjOteMJHUxs93hlVj3Am+Z2Z3Zjsu5dPipKuea15fCzvNlQHeCq6yca1W8xeGccy4t3uJwzjmXFk8czjnn0uKJwznnXFo8cTjnnEuLJw7nnHNp8cThnHMuLf8fbSOCPYFeDEsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find N value\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "239ef245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.893 total time=   7.1s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.895 total time=   7.1s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.894 total time=   6.8s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.893 total time=   4.5s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=9, weights=uniform;, score=0.895 total time=   7.0s\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.881 total time=   4.9s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.884 total time=   5.2s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.881 total time=   4.6s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.883 total time=   3.6s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=9, weights=distance;, score=0.884 total time=   3.8s\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=11, weights=uniform;, score=0.894 total time=   4.6s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=11, weights=uniform;, score=0.895 total time=   4.3s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=11, weights=uniform;, score=0.894 total time=   4.6s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=11, weights=uniform;, score=0.894 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=11, weights=uniform;, score=0.895 total time=   3.4s\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=11, weights=distance;, score=0.884 total time=   3.7s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=11, weights=distance;, score=0.887 total time=   4.0s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=11, weights=distance;, score=0.882 total time=   4.2s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=11, weights=distance;, score=0.885 total time=   3.7s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=11, weights=distance;, score=0.887 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=13, weights=uniform;, score=0.894 total time=   3.7s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=13, weights=uniform;, score=0.895 total time=   3.9s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=13, weights=uniform;, score=0.895 total time=   4.7s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=13, weights=uniform;, score=0.895 total time=   3.7s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=13, weights=uniform;, score=0.896 total time=   3.8s\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=13, weights=distance;, score=0.886 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=13, weights=distance;, score=0.888 total time=   3.9s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=13, weights=distance;, score=0.883 total time=   3.9s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=13, weights=distance;, score=0.886 total time=   3.1s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=13, weights=distance;, score=0.889 total time=   3.3s\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.895 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.896 total time=   3.8s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.895 total time=   3.8s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.895 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=15, weights=uniform;, score=0.896 total time=   3.3s\n",
      "[CV 1/5] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.887 total time=   3.7s\n",
      "[CV 2/5] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.889 total time=   3.9s\n",
      "[CV 3/5] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.883 total time=   4.3s\n",
      "[CV 4/5] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.887 total time=   3.0s\n",
      "[CV 5/5] END leaf_size=30, n_neighbors=15, weights=distance;, score=0.889 total time=   3.3s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.893 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.895 total time=   4.5s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.894 total time=   4.2s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.893 total time=   4.3s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=9, weights=uniform;, score=0.895 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.881 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.884 total time=   4.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.881 total time=   4.4s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.883 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=9, weights=distance;, score=0.884 total time=   3.2s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.894 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.895 total time=   5.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.894 total time=   4.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.894 total time=   3.7s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=11, weights=uniform;, score=0.895 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.884 total time=   4.0s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.887 total time=   4.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.882 total time=   3.8s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.885 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=11, weights=distance;, score=0.887 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.894 total time=   4.1s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.895 total time=   4.1s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.895 total time=   4.2s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.895 total time=   3.8s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=13, weights=uniform;, score=0.896 total time=   3.8s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.886 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.888 total time=   4.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.883 total time=   4.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.886 total time=   3.8s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=13, weights=distance;, score=0.889 total time=   3.3s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.895 total time=   5.4s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.896 total time=   4.0s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.895 total time=   4.2s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.895 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=15, weights=uniform;, score=0.896 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.887 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.889 total time=   3.8s\n",
      "[CV 3/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.883 total time=   4.1s\n",
      "[CV 4/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.887 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=50, n_neighbors=15, weights=distance;, score=0.889 total time=   3.0s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.893 total time=   3.5s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.895 total time=   3.9s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.894 total time=   4.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.893 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=9, weights=uniform;, score=0.895 total time=   3.4s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.881 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.884 total time=   3.5s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.881 total time=   3.6s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.883 total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END leaf_size=100, n_neighbors=9, weights=distance;, score=0.884 total time=   3.1s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.894 total time=   3.7s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.895 total time=   4.5s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.894 total time=   3.9s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.894 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=uniform;, score=0.895 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.884 total time=   4.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.887 total time=   4.1s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.882 total time=   4.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.885 total time=   3.2s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=11, weights=distance;, score=0.887 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.894 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.895 total time=   4.0s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.895 total time=   5.7s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.895 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=13, weights=uniform;, score=0.896 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.886 total time=   4.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.888 total time=   4.8s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.883 total time=   4.2s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.886 total time=   3.6s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=13, weights=distance;, score=0.889 total time=   3.4s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.895 total time=   4.0s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.896 total time=   3.8s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.895 total time=   4.0s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.895 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=uniform;, score=0.896 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.887 total time=   3.8s\n",
      "[CV 2/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.889 total time=   3.9s\n",
      "[CV 3/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.883 total time=   4.1s\n",
      "[CV 4/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.887 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=100, n_neighbors=15, weights=distance;, score=0.889 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=9, weights=uniform;, score=0.893 total time=   3.7s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=9, weights=uniform;, score=0.895 total time=   4.0s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=9, weights=uniform;, score=0.894 total time=   4.6s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=9, weights=uniform;, score=0.893 total time=   3.4s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=9, weights=uniform;, score=0.895 total time=   3.8s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=9, weights=distance;, score=0.881 total time=   4.2s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=9, weights=distance;, score=0.884 total time=   4.0s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=9, weights=distance;, score=0.881 total time=   4.4s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=9, weights=distance;, score=0.883 total time=   4.4s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=9, weights=distance;, score=0.884 total time=   3.9s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=11, weights=uniform;, score=0.894 total time=   4.2s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=11, weights=uniform;, score=0.895 total time=   4.3s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=11, weights=uniform;, score=0.894 total time=   4.1s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=11, weights=uniform;, score=0.894 total time=   3.5s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=11, weights=uniform;, score=0.895 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=11, weights=distance;, score=0.884 total time=   3.8s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=11, weights=distance;, score=0.887 total time=   4.0s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=11, weights=distance;, score=0.882 total time=   3.7s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=11, weights=distance;, score=0.885 total time=   3.1s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=11, weights=distance;, score=0.887 total time=   3.2s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=13, weights=uniform;, score=0.894 total time=   3.9s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=13, weights=uniform;, score=0.895 total time=   3.7s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=13, weights=uniform;, score=0.895 total time=   3.8s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=13, weights=uniform;, score=0.895 total time=   3.8s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=13, weights=uniform;, score=0.896 total time=   3.6s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=13, weights=distance;, score=0.886 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=13, weights=distance;, score=0.888 total time=   4.2s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=13, weights=distance;, score=0.883 total time=   3.8s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=13, weights=distance;, score=0.886 total time=   3.1s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=13, weights=distance;, score=0.889 total time=   3.5s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=15, weights=uniform;, score=0.895 total time=   4.2s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=15, weights=uniform;, score=0.896 total time=   4.2s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=15, weights=uniform;, score=0.895 total time=   4.1s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=15, weights=uniform;, score=0.895 total time=   3.2s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=15, weights=uniform;, score=0.896 total time=   3.3s\n",
      "[CV 1/5] END leaf_size=200, n_neighbors=15, weights=distance;, score=0.887 total time=   3.6s\n",
      "[CV 2/5] END leaf_size=200, n_neighbors=15, weights=distance;, score=0.889 total time=   3.6s\n",
      "[CV 3/5] END leaf_size=200, n_neighbors=15, weights=distance;, score=0.883 total time=   3.9s\n",
      "[CV 4/5] END leaf_size=200, n_neighbors=15, weights=distance;, score=0.887 total time=   3.7s\n",
      "[CV 5/5] END leaf_size=200, n_neighbors=15, weights=distance;, score=0.889 total time=   3.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'leaf_size': [30, 50, 100, 200],\n",
       "                         'n_neighbors': [9, 11, 13, 15],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= KNeighborsClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': [9,11,13,15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': [30, 50, 100, 200]\n",
    "}\n",
    "knn_grid_clf = GridSearchCV(model, param_grid, verbose=3)\n",
    "knn_grid_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84c5e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'leaf_size': 30, 'n_neighbors': 15, 'weights': 'uniform'}\n",
      "0.8950933333333333\n"
     ]
    }
   ],
   "source": [
    "print(knn_grid_clf.best_params_)\n",
    "print(knn_grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a131f2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8958133333333334\n",
      "Testing Data Score: 0.8928\n"
     ]
    }
   ],
   "source": [
    "knn_best_params=knn_grid_clf.best_params_\n",
    "kn_classifier= KNeighborsClassifier(**knn_best_params).fit(X_train_scaled, y_train)\n",
    "print(f\"Training Data Score: {kn_classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {kn_classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90390560",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(kn_classifier, open('Resources/kn_classifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8667e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510da389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
